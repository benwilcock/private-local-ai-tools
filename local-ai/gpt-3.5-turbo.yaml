# backend: llama
context_size: 4098
name: gpt-3.5-turbo
parameters:
  model: open-llama-7B-open-instruct.ggmlv3.q4_0.bin
  temperature: 0.2
  top_k: 80
  top_p: 0.7
template:
  chat: openllama-instruct-chat
  completion: openllama-instruct-completion
